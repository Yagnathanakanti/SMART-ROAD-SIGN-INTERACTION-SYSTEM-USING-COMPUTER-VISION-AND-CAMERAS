{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmftZ6dKoKMD",
        "outputId": "8674304f-1a04-44c2-ea74-9c9b39f368b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy pandas matplotlib seaborn scikit-learn opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQIXR9jeoNrt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_x8enjrtckS",
        "outputId": "23950ce0-51f8-422e-b4e5-3adad54babce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMBkfI7O1mMa"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Train1.zip\" /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhJOJPYN1tFO"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/Train1.zip -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGoYlh4y1zHl",
        "outputId": "8956fc80-3d47-47c7-f46c-e416cada6e7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.config', 'Train1.zip', 'drive', 'Train1', 'sample_data']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('/content/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chrZ-RKV15oj",
        "outputId": "0979feab-934e-4ecd-9ce8-6f5726773ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Loaded: 5429 images\n",
            "Train Set: (4343, 32, 32, 1), Test Set: (1086, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "IMG_SIZE = 32\n",
        "TRAIN_DIR = \"/content/Train1\"\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "categories = sorted(os.listdir(TRAIN_DIR))\n",
        "\n",
        "def process_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "\n",
        "    blurred = cv2.GaussianBlur(equalized, (3, 3), 0)\n",
        "\n",
        "    final_img = blurred.astype('float32') / 255.0\n",
        "    return np.expand_dims(final_img, axis=-1)\n",
        "\n",
        "for category in categories:\n",
        "    class_path = os.path.join(TRAIN_DIR, category)\n",
        "    img_paths = glob.glob(os.path.join(class_path, \"*.png\")) + \\\n",
        "                glob.glob(os.path.join(class_path, \"*.jpg\")) + \\\n",
        "                glob.glob(os.path.join(class_path, \"*.jpeg\"))\n",
        "\n",
        "    for img_path in img_paths:\n",
        "        processed_img = process_image(img_path)\n",
        "        if processed_img is not None:\n",
        "            data.append(processed_img)\n",
        "            labels.append(category)\n",
        "\n",
        "data = np.array(data, dtype='float32')\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(labels)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split dataset (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "print(f\"Dataset Loaded: {len(data)} images\")\n",
        "print(f\"Train Set: {X_train.shape}, Test Set: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7xpyxdq3RrH",
        "outputId": "05dcbc3a-02c1-4d91-aa1c-9c0089baefae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5429 5429\n",
            "{np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)}\n",
            "Number of classes: 6\n"
          ]
        }
      ],
      "source": [
        "NUM_CLASSES = len(set(y_train))\n",
        "print(len(data), len(labels))\n",
        "print(set(labels))\n",
        "print(\"Number of classes:\", NUM_CLASSES)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyBgh1O13kaB",
        "outputId": "0aaeefae-f113-46f3-fe20-62971747523e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data Shape: (4343, 32, 32, 1)\n",
            "Training Labels Shape: (4343,)\n",
            "Testing Data Shape: (1086, 32, 32, 1)\n",
            "Testing Labels Shape: (1086,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Training Labels Shape:\", y_train.shape)\n",
        "print(\"Testing Data Shape:\", X_test.shape)\n",
        "print(\"Testing Labels Shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge1tJ4xpZgiE"
      },
      "outputs": [],
      "source": [
        "# Reshape data for CNN (Ensure proper format)\n",
        "X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # Add channel dimension\n",
        "X_test = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv8RahvTZtN8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV5DDSMZZfIE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "BqFdSG3a3pgp",
        "outputId": "c7c259bf-3f6c-49b9-e069-2122794a4836"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,110</span> (621.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m159,110\u001b[0m (621.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,110</span> (621.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m159,110\u001b[0m (621.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Prevent overfitting\n",
        "    Dense(len(categories), activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcf1qW40Z6_e",
        "outputId": "bd4a2dfc-3246-49d5-a1b9-bf690f98bbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.5368 - loss: 1.2821 - val_accuracy: 0.9328 - val_loss: 0.2822\n",
            "Epoch 2/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9198 - loss: 0.2817 - val_accuracy: 0.9595 - val_loss: 0.1278\n",
            "Epoch 3/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.9599 - loss: 0.1362 - val_accuracy: 0.9742 - val_loss: 0.0699\n",
            "Epoch 4/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.9840 - loss: 0.0617 - val_accuracy: 0.9917 - val_loss: 0.0352\n",
            "Epoch 5/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.9846 - loss: 0.0424 - val_accuracy: 0.9926 - val_loss: 0.0341\n",
            "Epoch 6/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9946 - loss: 0.0232 - val_accuracy: 0.9926 - val_loss: 0.0408\n",
            "Epoch 7/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9946 - loss: 0.0189 - val_accuracy: 0.9945 - val_loss: 0.0218\n",
            "Epoch 8/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.9959 - loss: 0.0133 - val_accuracy: 0.9926 - val_loss: 0.0310\n",
            "Epoch 9/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9954 - val_loss: 0.0219\n",
            "Epoch 10/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.9954 - val_loss: 0.0194\n",
            "Epoch 11/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9982 - val_loss: 0.0202\n",
            "Epoch 12/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - accuracy: 0.9998 - loss: 0.0028 - val_accuracy: 0.9982 - val_loss: 0.0215\n",
            "Epoch 13/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.9973 - loss: 0.0058 - val_accuracy: 0.9972 - val_loss: 0.0214\n",
            "Epoch 14/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9972 - val_loss: 0.0234\n",
            "Epoch 15/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9972 - val_loss: 0.0211\n",
            "Epoch 16/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9998 - loss: 9.2229e-04 - val_accuracy: 0.9972 - val_loss: 0.0227\n",
            "Epoch 17/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9945 - val_loss: 0.0226\n",
            "Epoch 18/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9954 - val_loss: 0.0196\n",
            "Epoch 19/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.2381e-04 - val_accuracy: 0.9972 - val_loss: 0.0219\n",
            "Epoch 20/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6189e-04 - val_accuracy: 0.9982 - val_loss: 0.0203\n",
            "Epoch 21/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.9926 - val_loss: 0.0378\n",
            "Epoch 22/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9947 - loss: 0.0153 - val_accuracy: 0.9936 - val_loss: 0.0319\n",
            "Epoch 23/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0108 - val_accuracy: 0.9982 - val_loss: 0.0165\n",
            "Epoch 24/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9982 - val_loss: 0.0155\n",
            "Epoch 25/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9982 - val_loss: 0.0174\n",
            "Epoch 26/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.3368e-04 - val_accuracy: 0.9982 - val_loss: 0.0159\n",
            "Epoch 27/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.5189e-04 - val_accuracy: 0.9982 - val_loss: 0.0164\n",
            "Epoch 28/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.5245e-05 - val_accuracy: 0.9982 - val_loss: 0.0184\n",
            "Epoch 29/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 3.0727e-04 - val_accuracy: 0.9982 - val_loss: 0.0156\n",
            "Epoch 30/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.5993e-05 - val_accuracy: 0.9982 - val_loss: 0.0177\n",
            "Epoch 31/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2285e-04 - val_accuracy: 0.9982 - val_loss: 0.0195\n",
            "Epoch 32/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.0287e-04 - val_accuracy: 0.9982 - val_loss: 0.0203\n",
            "Epoch 33/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7311e-04 - val_accuracy: 0.9982 - val_loss: 0.0240\n",
            "Epoch 34/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 5.0557e-05 - val_accuracy: 0.9982 - val_loss: 0.0235\n",
            "Epoch 35/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6928e-05 - val_accuracy: 0.9982 - val_loss: 0.0242\n",
            "Epoch 36/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 6.7530e-05 - val_accuracy: 0.9982 - val_loss: 0.0236\n",
            "Epoch 37/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7594e-05 - val_accuracy: 0.9982 - val_loss: 0.0252\n",
            "Epoch 38/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.3798e-05 - val_accuracy: 0.9982 - val_loss: 0.0218\n",
            "Epoch 39/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.1948e-05 - val_accuracy: 0.9982 - val_loss: 0.0246\n",
            "Epoch 40/40\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9975 - loss: 0.0086 - val_accuracy: 0.9954 - val_loss: 0.0170\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_rtR2Gn6Pc7",
        "outputId": "6ec33402-129d-43e0-95ff-b6faa9b2b0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9946 - loss: 0.0182\n",
            "Test Accuracy: 99.54%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0purvLt6W4t"
      },
      "outputs": [],
      "source": [
        "model.save(\"image_detection_model.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynHM33On7hRe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/image_detection_model.keras\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B13gxPZYFTnC",
        "outputId": "d7a3b876-5c5b-4b98-cd42-d6d8e937dcbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  image_detection_model.keras  sample_data  Train1  Train1.zip\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "m-_WejcE9pow",
        "outputId": "852b15f1-e876-4200-9232-5dd8b0543b4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cbba9966-ca1a-4d89-ba27-bff2d5db5149\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cbba9966-ca1a-4d89-ba27-bff2d5db5149\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 00034_00000_00000.png to 00034_00000_00000.png\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPOdZKCEbcGH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZPnzjr96WT",
        "outputId": "fe0451f0-cdac-49d9-cbbc-6ef0fc39d3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "Predicted Class: 1\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/traffic_sign_model.keras\")\n",
        "\n",
        "image_path = \"00001.png\"\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "if img is None:\n",
        "    print(\"Error: Image not loaded. Check filename.\")\n",
        "else:\n",
        "    print(\"Image loaded successfully!\")\n",
        "\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "q6c5hk-t_2FG",
        "outputId": "183b3d05-8fbe-4127-8c7f-719e93649c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: Turn left ahead\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"image_detection_model.keras\")\n",
        "\n",
        "image_path = \"00034_00000_00000.png\"\n",
        "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "if img is None:\n",
        "    print(\"Error: Image not loaded. Check filename or path.\")\n",
        "else:\n",
        "    print(\"Image loaded successfully!\")\n",
        "\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Class Labels\n",
        "    classes = {\n",
        "        0:'Speed limit (20km/h)', 1:'Speed limit (30km/h)', 2:'Stop',\n",
        "        3:'No entry', 4:'Turn right ahead', 5:'Turn left ahead'\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(img[0, :, :, 0], cmap=\"gray\")\n",
        "    plt.title(f\"Detected Traffic Sign: {classes[predicted_class]}\", fontsize=12, color=\"red\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Predicted Class: {classes[predicted_class]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw2_b_gfMpPx",
        "outputId": "c19ed953-2247-4069-d8ea-f7caa3e4f29f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/tomlkit/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "6WLz6FS3hx1g",
        "outputId": "d1ec7571-188c-4e54-aca5-e1f78af81d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3b06fb0e64fec9e680.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3b06fb0e64fec9e680.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"image_detection_model.keras\")\n",
        "\n",
        "# Class Labels\n",
        "classes = {\n",
        "    0:'Speed limit (20km/h)', 1:'Speed limit (30km/h)', 2:'Stop',\n",
        "    3:'No entry', 4:'Turn right ahead', 5:'Turn left ahead'\n",
        "\n",
        "}\n",
        "\n",
        "def predict_image(image):\n",
        "\n",
        "    img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    return f\"Detected Traffic Sign: {classes[predicted_class]}\"\n",
        "\n",
        "iface = gr.Interface(fn=predict_image, inputs=gr.Image(), outputs=\"text\")\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}